# -*- coding: utf-8 -*-
"""Detect Spam Emails.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YrrCSMQOQAO-JuSFUYMafy16pKlTVE_0

# 1. Define the Problem

To begin with, the problem of detecting spam emails can be defined as a binary classification task where the goal is to automatically differentiate between legitimate emails (ham) and unsolicited or malicious emails (spam). This problem is crucial in ensuring the security and efficiency of email communication systems, as spam emails can clutter users' inboxes, waste time, and potentially contain harmful content such as phishing attempts or malware. The objective is to develop a robust machine learning model, leveraging techniques from data science and artificial intelligence, to accurately classify incoming emails in real-time, thereby allowing users to maintain a clean and secure inbox while minimizing the risk of exposure to fraudulent or unwanted content.

**0** : ham

**1** : spam

## Goals

Using Tensorflow tool, how can you detect spam emails automatically so the user’s inbox remains clean? Perform EDA on dataset to detect spam mail

# 2. Explore the Data

## import
"""

import pandas as pd
from matplotlib import pyplot as plt

from wordcloud import WordCloud

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from tqdm import tqdm
import re

from imblearn.over_sampling import SMOTE

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D
from tensorflow.keras.optimizers import Adam

"""## data"""

df = pd.read_csv("./Emails.csv")

df

df.info()

df.describe()

"""std = The standard deviation σ is the square root of the variance"""

# @title The distribution of values in the 'spam' column

df['spam'].plot(kind='hist', title='spam')

# modifies the plot's axis spines to make them invisible on the top and right sides.
plt.gca().spines[['top', 'right',]].set_visible(False)

# @title Calculate the percentage distribution
percentage_distribution = df['spam'].value_counts(normalize=True) * 100

# Plot the percentage distribution as a bar chart
percentage_distribution.plot(kind='bar', title='Percentage distribution of spam')

# Add labels to the axes
plt.xlabel('Spam Values')
plt.ylabel('Percentage')

# Show the plot
plt.show()

"""**N.B:**

- In the context of a histogram, bins refer to the intervals into which the data range is divided. When you create a histogram, you're essentially plotting the frequency distribution of a dataset. Bins help you organize the data into groups or intervals, and each bin represents a range of values.

- For example, if you have a dataset ranging from 0 to 100 and you specify 10 bins, the data will be divided into 10 intervals of width 10 each: 0-10, 10-20, 20-30, and so on up to 90-100. The histogram will then count the number of data points falling within each interval and represent it as a bar.
"""

print(percentage_distribution)

"""The dataset consists of approximately 76% non-spam emails and 24% spam emails. This indicates a class imbalance, with a higher proportion of non-spam emails. When building and evaluating the model, it's important to consider this imbalance to ensure the model performs well on both classes."""

# plt.hist(df['spam'])
# plt.title("SPAM")
# plt.xlabel("1 or 0")
# plt.ylabel("Frequency")
# plt.show()

# @title Word Cloud of Spam Emails : ham

text = ' '.join(df[df['spam'] == 1]['text'].tolist())
wordcloud = WordCloud().generate(text)
plt.imshow(wordcloud)
_ = plt.axis('off')

# @title Word Cloud of Spam Emails : spam

text = ' '.join(df[df['spam'] == 0]['text'].tolist())
wordcloud = WordCloud().generate(text)
plt.imshow(wordcloud)
_ = plt.axis('off')

"""# 3. Data Cleaning and Preprocessing

## Missing Data
"""

df.isnull().sum()

"""## NLP Preprocessing"""

tqdm.pandas()

# Function to clean the text data
def clean_text(text):
    text = text.lower() # Convert to lowercase
    text = re.sub(r'\W', ' ', text) # Remove all non-word characters
    text = re.sub(r'\s+', ' ', text) # Replace all runs of whitespaces with a single space
    return text

# Clean the 'text' column
df['text_clean'] = df['text'].progress_apply(clean_text)

"""# 4. Feature Engineering

## Add the column: number of words
"""

# Function to count words in a text
def count_words(text):
    return len(text.split())

# Apply the function to each row in the 'text' column and create a new column 'word_count'
df['word_count'] = df['text_clean'].apply(count_words)

df

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(df['text_clean'], df['spam'], test_size=0.2, random_state=42)
# X_train, X_test, y_train, y_test = train_test_split(df[['text_clean','word_count']], df['spam'], test_size=0.2, random_state=42)

# Initialize the TF-IDF Vectorizer
vectorizer = TfidfVectorizer(max_features=5000)

# Fit and transform the training data
X_train_tfidf = vectorizer.fit_transform(X_train)
# X_train_tfidf = vectorizer.fit_transform(X_train['text_clean'])

# Transform the testing data
X_test_tfidf = vectorizer.transform(X_test)
# X_test_tfidf = vectorizer.transform(X_test['text_clean'])

X_train

y_train

"""## Imbalanced Dataset"""

percentage_distribution = y_train.value_counts(normalize=True) * 100

print(percentage_distribution)

smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train_tfidf, y_train)

percentage_distribution = y_train_res.value_counts(normalize=True) * 100

print(percentage_distribution)

"""# 5. Exploratory Data Analysis"""

percentage_distribution.plot(kind='bar', title='Percentage distribution of spam')

# Add labels to the axes
plt.xlabel('Spam Values')
plt.ylabel('Percentage')

# Show the plot
plt.show()

# @title Word Cloud of Spam Emails

text = ' '.join(X_train['text_clean'].tolist())
wordcloud = WordCloud().generate(text)
plt.imshow(wordcloud)
_ = plt.axis('off')

"""# 6. Model Selection"""

# the size of your vocabulary
vocab_size = 10000
# the dimension for word embeddings
embedding_dim = 16

model = Sequential([
    # Embedding layer for text inputs
    Embedding(vocab_size, embedding_dim, input_length=5000),
    # Global average pooling to reduce tensor dimensionality
    GlobalAveragePooling1D(),
    # Dense layer with 24 units and ReLU activation
    Dense(24, activation='relu'),
    # Output layer with sigmoid activation for binary classification
    Dense(1, activation='sigmoid')
])

# Compile the model with binary crossentropy loss and an Adam optimizer
model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])

# Summary of the model
model.summary()

"""The model we've designed for spam detection is a simple neural network that consists of the following layers:

- **Embedding Layer**: This is the first layer of our model, which turns positive integers (indexes) into dense vectors of fixed size. This layer is crucial for text processing tasks, as it allows the model to interpret words in a meaningful way. The `vocab_size` parameter defines the size of the vocabulary in the text data, and `embedding_dim` specifies the dimensionality of the embedding vectors. The `input_length` is the length of input sequences, which should be consistent across all samples by padding shorter sequences or truncating longer ones.

- **GlobalAveragePooling1D Layer**: This layer reduces the dimensionality of the input by taking the average over the time dimension, which helps to minimize overfitting by reducing the total number of parameters in the model.

- **Dense Layer**: A fully connected layer that comes after the pooling layer. It has 24 units and uses the ReLU activation function. This layer's purpose is to learn non-linear combinations of the high-level features extracted by the previous layers.

- **Output Layer**: The final layer is another dense layer with a single unit and a sigmoid activation function. This setup is typical for binary classification problems, where the model outputs a probability indicating the likelihood of the input being in one class (spam) or the other (non-spam).

The model uses the binary crossentropy loss function, which is appropriate for binary classification problems. The Adam optimizer is used for training, with a learning rate of 0.001, which is a common choice for many types of neural networks.

# 7. Model Training
"""

X_train_res_dense = X_train_res.toarray()
X_test_tfidf_dense = X_test_tfidf.toarray()

history = model.fit(X_train_res_dense, y_train_res, epochs=100, validation_data=(X_test_tfidf_dense, y_test), batch_size=32)

"""# 8. Model Evaluation"""

val_loss, val_accuracy = model.evaluate(X_test_tfidf_dense, y_test)
print(f'Validation Loss: {val_loss}')
print(f'Validation Accuracy: {val_accuracy}')

"""# 9. Iterate and Refine"""

history = model.fit(X_train_res_dense, y_train_res, epochs=2, validation_data=(X_test_tfidf_dense, y_test), batch_size=32)

val_loss, val_accuracy = model.evaluate(X_test_tfidf_dense, y_test)
print(f'Validation Loss: {val_loss}')
print(f'Validation Accuracy: {val_accuracy}')

"""# 10. Communicate Results

The results from training your model show a validation loss of 0.6927844285964966 and a validation accuracy of 74.69%. Here's what these metrics tell us:

- **Validation Loss**: This metric represents how well the model is performing on the validation dataset, with lower values indicating better performance. A loss of approximately 0.69 suggests that there is room for improvement in the model's ability to predict spam accurately. The loss value is close to 0.693, which is the loss of a model that predicts randomly for a binary classification problem, indicating that the model might not be learning as effectively as desired from the training data.

- **Validation Accuracy**: This metric shows the percentage of correct predictions made by the model on the validation dataset. An accuracy of 74.69% means that the model correctly predicts whether an email is spam or not about three-quarters of the time. While this is a decent starting point, there is certainly scope for improvement to make the model more reliable.

To improve these metrics, consider the following strategies:
- **Model Architecture**: Experiment with different model architectures, including adding more layers, changing the number of units in dense layers, or using different types of layers (e.g., LSTM or Conv1D for sequence data).
- **Hyperparameter Tuning**: Adjust learning rate, batch size, and other hyperparameters to find a better performing model.
- **Regularization**: Implement dropout or L2 regularization to prevent overfitting, especially if your model is complex.
- **Data Augmentation**: For text data, consider techniques like synonym replacement, sentence shuffling, or back translation to increase the diversity of your training data.
- **Class Weights**: Since you mentioned dealing with an imbalanced dataset, ensure that class weights are properly utilized during training to give more importance to underrepresented classes.

Improving a model is an iterative process that involves experimenting with different configurations and techniques.
"""